{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code maps the data set types to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "val stringLabels = mapOf(\n",
    "    0 to \"T-shirt/top\",\n",
    "    1 to \"Trousers\",\n",
    "    2 to \"Pullover\",\n",
    "    3 to \"Dress\",\n",
    "    4 to \"Coat\",\n",
    "    5 to \"Sandals\",\n",
    "    6 to \"Shirt\",\n",
    "    7 to \"Sneakers\",\n",
    "    8 to \"Bag\",\n",
    "    9 to \"Ankle boots\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code adds the KotlinDL API for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@file:DependsOn(\"org.jetbrains.kotlinx:kotlin-deeplearning-tensorflow:0.5.2\")\n",
    "%use kotlin-dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates the model to be used for the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val model = Sequential.of(\n",
    "    Input(28, 28, 1), // Input dimensions as 28x28 image of thickness 1\n",
    "    org.jetbrains.kotlinx.dl.api.core.layer.reshaping.Flatten(), // Remap input to 1D list of bytes\n",
    "    Dense(250), // Arbitrary choice of processing layer\n",
    "    Dense(250), // Arbitrary choice of processing layer\n",
    "    Dense(10), // Output layer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 60000 images of 28x28 from H:\\Kotlin\\FirstNeuralNetwork\\cache\\datasets\\fashionmnist\\train-images-idx3-ubyte.gz\n",
      "Extracting 60000 labels from H:\\Kotlin\\FirstNeuralNetwork\\cache\\datasets\\fashionmnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting 10000 images of 28x28 from H:\\Kotlin\\FirstNeuralNetwork\\cache\\datasets\\fashionmnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting 10000 labels from H:\\Kotlin\\FirstNeuralNetwork\\cache\\datasets\\fashionmnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "val (train, test) = fashionMnist() // Do it here to reference from everywhere else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code trains and tests the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================\n",
      "Model type: Sequential\n",
      "______________________________________________________________________________\n",
      "Layer (type)                           Output Shape              Param #      \n",
      "==============================================================================\n",
      "input_1(Input)                         [None, 28, 28, 1]         0            \n",
      "______________________________________________________________________________\n",
      "flatten_2(Flatten)                     [None, 784]               0            \n",
      "______________________________________________________________________________\n",
      "dense_3(Dense)                         [None, 250]               196250       \n",
      "______________________________________________________________________________\n",
      "dense_4(Dense)                         [None, 250]               62750        \n",
      "______________________________________________________________________________\n",
      "dense_5(Dense)                         [None, 10]                2510         \n",
      "______________________________________________________________________________\n",
      "==============================================================================\n",
      "Total trainable params: 261510\n",
      "Total frozen params: 0\n",
      "Total params: 261510\n",
      "______________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import java.io.File\n",
    "\n",
    "model.use {\n",
    "    it.compile(\n",
    "        optimizer = Adam(),\n",
    "        loss = Losses.SOFT_MAX_CROSS_ENTROPY_WITH_LOGITS,\n",
    "        metric = Metrics.ACCURACY\n",
    "    ) // Compiles the model with the ADAM optimiser algorithm and uses accuracy as metric\n",
    "\n",
    "    it.printSummary() // Prints out model information\n",
    "\n",
    "    it.fit(\n",
    "        dataset = train, // Use the train set to fit to the model\n",
    "        epochs = 50, // Number of full cycles of data fitting\n",
    "        batchSize = 200 // How big one batch of data should be\n",
    "    )\n",
    "\n",
    "    val accuracy = it.evaluate(dataset = test, batchSize = 200).metrics[Metrics.ACCURACY] // Evaluate model\n",
    "\n",
    "    println(\"Accuracy: $accuracy\") // Print out the accuracy\n",
    "    it.save(File(\"model/my_model\"), writingMode = WritingMode.OVERRIDE) // Save the model to a file to reference it later\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is an example of how to load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 60000 images of 28x28 from H:\\Kotlin\\FirstNeuralNetwork\\cache\\datasets\\fashionmnist\\train-images-idx3-ubyte.gz\n",
      "Extracting 60000 labels from H:\\Kotlin\\FirstNeuralNetwork\\cache\\datasets\\fashionmnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting 10000 images of 28x28 from H:\\Kotlin\\FirstNeuralNetwork\\cache\\datasets\\fashionmnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting 10000 labels from H:\\Kotlin\\FirstNeuralNetwork\\cache\\datasets\\fashionmnist\\t10k-labels-idx1-ubyte.gz\n",
      "Predicted label is: 1. This corresponds to class Trousers.\n",
      "Actual label is: 1.0.\n"
     ]
    }
   ],
   "source": [
    "import java.io.File\n",
    "\n",
    "// val (train, test) = fashionMnist() done above, so don't repeat it here as expensive calculation\n",
    "\n",
    "org.jetbrains.kotlinx.dl.api.inference.TensorFlowInferenceModel.load(File(\"model/my_model\")).use {\n",
    "    it.reshape(28, 28, 1)\n",
    "    val prediction = it.predict(test.getX(5))\n",
    "    val actualLabel = test.getY(5)\n",
    "\n",
    "    println(\"Predicted label is: $prediction. This corresponds to class ${stringLabels[prediction]}.\")\n",
    "    println(\"Actual label is: $actualLabel.\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will go through the test data and plot the predicted results from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "   <div id=\"prD2vP\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "       if(!window.letsPlotCallQueue) {\n",
       "           window.letsPlotCallQueue = [];\n",
       "       }; \n",
       "       window.letsPlotCall = function(f) {\n",
       "           window.letsPlotCallQueue.push(f);\n",
       "       };\n",
       "       (function() {\n",
       "           var script = document.createElement(\"script\");\n",
       "           script.type = \"text/javascript\";\n",
       "           script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v3.2.0/js-package/distr/lets-plot.min.js\";\n",
       "           script.onload = function() {\n",
       "               window.letsPlotCall = function(f) {f();};\n",
       "               window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "               window.letsPlotCallQueue = [];\n",
       "               \n",
       "               \n",
       "           };\n",
       "           script.onerror = function(event) {\n",
       "               window.letsPlotCall = function(f) {};\n",
       "               window.letsPlotCallQueue = [];\n",
       "               var div = document.createElement(\"div\");\n",
       "               div.style.color = 'darkred';\n",
       "               div.textContent = 'Error loading Lets-Plot JS';\n",
       "               document.getElementById(\"prD2vP\").appendChild(div);\n",
       "           };\n",
       "           var e = document.getElementById(\"prD2vP\");\n",
       "           e.appendChild(script);\n",
       "       })();\n",
       "   </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%use lets-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 60000 images of 28x28 from H:\\Kotlin\\FirstNeuralNetwork\\cache\\datasets\\fashionmnist\\train-images-idx3-ubyte.gz\n",
      "Extracting 60000 labels from H:\\Kotlin\\FirstNeuralNetwork\\cache\\datasets\\fashionmnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting 10000 images of 28x28 from H:\\Kotlin\\FirstNeuralNetwork\\cache\\datasets\\fashionmnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting 10000 labels from H:\\Kotlin\\FirstNeuralNetwork\\cache\\datasets\\fashionmnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "   <div id=\"xBjtzQ\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"plot\">\n",
       "       (function() {\n",
       "           var plotSpec={\n",
       "\"mapping\":{\n",
       "},\n",
       "\"data\":{\n",
       "},\n",
       "\"kind\":\"plot\",\n",
       "\"scales\":[{\n",
       "\"aesthetic\":\"x\",\n",
       "\"discrete\":true\n",
       "},{\n",
       "\"aesthetic\":\"y\"\n",
       "}],\n",
       "\"layers\":[{\n",
       "\"mapping\":{\n",
       "\"x\":\"x\"\n",
       "},\n",
       "\"stat\":\"count\",\n",
       "\"color\":\"dark_green\",\n",
       "\"alpha\":0.3,\n",
       "\"position\":\"stack\",\n",
       "\"geom\":\"bar\",\n",
       "\"fill\":\"dark_green\",\n",
       "\"data\":{\n",
       "\"..count..\":[7222.0,8222.0,7015.0,6587.0,6964.0,7247.0,6795.0,6824.0,6142.0,6982.0],\n",
       "\"x\":[\"Ankle boots\",\"T-shirt/top\",\"Dress\",\"Pullover\",\"Sneakers\",\"Coat\",\"Sandals\",\"Trousers\",\"Shirt\",\"Bag\"]\n",
       "}\n",
       "}]\n",
       "};\n",
       "           var plotContainer = document.getElementById(\"xBjtzQ\");\n",
       "           window.letsPlotCall(function() {{\n",
       "               LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer);\n",
       "           }});\n",
       "       })();    \n",
       "   </script>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val `data` = mutableListOf<String>()\n",
    "\n",
    "// val (train, test) = fashionMnist() done above, so don't repeat it here, as it is an expensive calculation\n",
    "\n",
    "org.jetbrains.kotlinx.dl.api.inference.TensorFlowInferenceModel.load(File(\"model/my_model\")).use {\n",
    "    it.reshape(28, 28, 1)\n",
    "    for (i in 0 until train.xSize()) {\n",
    "        `data`.add(stringLabels[it.predict(train.getX(i)).toInt()]!!)\n",
    "    }\n",
    "    for (i in 0 until test.xSize()) {\n",
    "        `data`.add(stringLabels[it.predict(test.getX(i)).toInt()]!!)\n",
    "    }\n",
    "}\n",
    "\n",
    "val plot = letsPlot(mapOf(\"x\" to `data`)) +\n",
    "    geomBar(fill = \"dark_green\", color = \"dark_green\", alpha = 0.3) {\n",
    "        x = \"x\"\n",
    "    } + \n",
    "    scaleXDiscrete() + \n",
    "    scaleYContinuous()\n",
    "    \n",
    "(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 60000 images of 28x28 from H:\\Kotlin\\FirstNeuralNetwork\\cache\\datasets\\fashionmnist\\train-images-idx3-ubyte.gz\n",
      "Extracting 60000 labels from H:\\Kotlin\\FirstNeuralNetwork\\cache\\datasets\\fashionmnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting 10000 images of 28x28 from H:\\Kotlin\\FirstNeuralNetwork\\cache\\datasets\\fashionmnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting 10000 labels from H:\\Kotlin\\FirstNeuralNetwork\\cache\\datasets\\fashionmnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "   <div id=\"BAD5GI\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"plot\">\n",
       "       (function() {\n",
       "           var plotSpec={\n",
       "\"mapping\":{\n",
       "},\n",
       "\"data\":{\n",
       "},\n",
       "\"kind\":\"plot\",\n",
       "\"scales\":[{\n",
       "\"aesthetic\":\"x\",\n",
       "\"discrete\":true\n",
       "},{\n",
       "\"aesthetic\":\"y\"\n",
       "}],\n",
       "\"layers\":[{\n",
       "\"mapping\":{\n",
       "\"x\":\"x\"\n",
       "},\n",
       "\"stat\":\"count\",\n",
       "\"color\":\"dark_green\",\n",
       "\"alpha\":0.3,\n",
       "\"position\":\"stack\",\n",
       "\"geom\":\"bar\",\n",
       "\"fill\":\"dark_green\",\n",
       "\"data\":{\n",
       "\"..count..\":[7000.0,7000.0,7000.0,7000.0,7000.0,7000.0,7000.0,7000.0,7000.0,7000.0],\n",
       "\"x\":[\"Ankle boots\",\"T-shirt/top\",\"Dress\",\"Pullover\",\"Sneakers\",\"Sandals\",\"Trousers\",\"Shirt\",\"Coat\",\"Bag\"]\n",
       "}\n",
       "}]\n",
       "};\n",
       "           var plotContainer = document.getElementById(\"BAD5GI\");\n",
       "           window.letsPlotCall(function() {{\n",
       "               LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer);\n",
       "           }});\n",
       "       })();    \n",
       "   </script>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val `data` = mutableListOf<String>()\n",
    "\n",
    "// val (train, test) = fashionMnist() done above, so don't do it here as expensive calculation\n",
    "\n",
    "org.jetbrains.kotlinx.dl.api.inference.TensorFlowInferenceModel.load(File(\"model/my_model\")).use {\n",
    "    it.reshape(28, 28, 1)\n",
    "    for (i in 0 until train.xSize()) {\n",
    "        `data`.add(stringLabels[train.getY(i).toInt()]!!)\n",
    "    }\n",
    "    for (i in 0 until test.xSize()) {\n",
    "        `data`.add(stringLabels[test.getY(i).toInt()]!!)\n",
    "    }\n",
    "}\n",
    "\n",
    "val plot = letsPlot(mapOf(\"x\" to `data`)) +\n",
    "    geomBar(fill = \"dark_green\", color = \"dark_green\", alpha = 0.3) {\n",
    "        x = \"x\"\n",
    "        \n",
    "    } + \n",
    "    scaleXDiscrete() + \n",
    "    scaleYContinuous()\n",
    "    \n",
    "(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "codemirror_mode": "text/x-kotlin",
   "file_extension": ".kt",
   "mimetype": "text/x-kotlin",
   "name": "kotlin",
   "nbconvert_exporter": "",
   "pygments_lexer": "kotlin",
   "version": "1.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
